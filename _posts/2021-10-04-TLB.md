---
layout:     post
author:     bcnote3314
title: 변환 색인 버퍼(Translation Lookaside Buffer, TLB)
subtitle:  성능을 올리기 위한 삽질 기록
category: Note
tags: 		OS Experiences
---

# 개요

성능을 올리기 위해 가장 처음 했던 것은 Cache Memory를 사용하는 것이였고, 두번재는 최대한 NUMA 구조의 이점을 활용하기 위한 형태를 만드는 것이었다.  

다음 개선 포인트는 [NUMA](https://y-jaehyun.github.io/experiences/2021/09/13/numa/)에서 잠깐 언급 되었던 Page Fault와 TLB Shootdown 의한 성능 저하 요소를 찾는 것이었다.  

두가지 사항에 대해서 고민하게 된 이유는 시험과정에서 발생한 특이한 현상 떄문이였다.  
성능 시험을 해보면 특정 주기마다 성능 수치가 일시적으로 떨어지는 현상이 보였다.  

가장 의심스러운 부분은 주기마다 동작하는 카운팅 및 로깅 처리를 위한 스레드가 원인으로 의심되었다.  
하지만 카운팅, 로깅 스레드는 실시간성 동작을 위한 것이 아니기 떄문에 실시간을 요하는 스레드에 영향을 주면 안되는 부분이며 일부 전역변수를 제외하고는 서로 연관되는 것이 없었다.  

해당 로직에서 의심되는 부분들을 조금씩 추려가며 원인이되는 동작을 찾아보니 memset이 원인 이였다.  
memset이 왜 다른 스레드 성능에 영향을 주었을까?

# Physical Memory, Virtual Memory 매핑 과정

![메모리](http://drive.google.com/uc?export=view&id=1kinuvajLNfiuf5UvmJKbmkuQ_3YOvfZz)

이것도 OS 수업시간에 분명 배운 개념이다. (물론 시험보고나서 쓸일이 없어 까먹은지 오래다.)  
Physical Memory(Main Memory, RAM)의 공간은 한정되어있다.  

한정된 공간이라는 한계를 극복하기 위하여 OS에서는 Virtual Memory 개념을 사용한다.  
상대적으로 넉넉한 공간(Secondary Storage, DISK)를 활용한다.  

일반적으로 프로그래밍을 하면서 보는 주소값은 Virtual Memory(Logical Memory)이다.  
OS에서는 Page 단위로 메모리 Block을 나누고 Virtaul Memory를 Physical Memory로 변환하는 역할을 수행한다.  

수행 순서는 다음과 같은 형태이다.  
우선 TLB(Translation Looksaside Buffer)라 칭하는 캐시에 저장된 정보를 확인한다.  
TLB HIT. 즉, 현재 가상 주소가 캐시 내에 존재하는 정보라면 바로 물리 주소로 매핑이 된다.  
하지만 TLB MISS가 발생한다면 Page Table을 조회하게 된다.
이미 기존에 접근했던 Page의 경우엔 이미 Physical Memory에 올라가 있을 것이고 Table에 매핑된 정보를 토대로 접근이 가능하다.  
하지만 아직 접근하지 않았거나, 오래전 접근하여이미 Physical Memory에서 이미 빠진 주소라면 Page Fault가 발생한다.  
Page Fault가 발생하면 하드디스크에서 해당 정보를 다시 읽어와야하며 Page Table도 갱신이 되어야한다. (LRU 등의 알고리즘을 통해 대체될것이다.)  

TLB는 Hardware Cache이기 때문에 속도가 상당히 빠르다.  
이전에 메모리 접근 속도의 향상을 위해 CPU Cache를 사용했던것과 비슷한 원리이다.  

즉 우리는 Cache Miss를 최대한 발생하지 않도록 노력했던것과 같이 TLB Miss를 줄이기 위한 노력을 해야한다.  
TLB 다음 조회하는 Page Table의 경우는 Cache가 아니기 때문에 비교적으로 느리다.  
하지만 PageTable 까지는 괜찮다.  
RAM이 느리다 느리다 했어도 디스크에 비할바는 아니다.  
만약 Page Fault가 발생하고 디스크에 접근을 해야한다면 그로 인한 속도 차이는 어마어마 할것이다.


# 문제점과 수정

내가 확인했던 코드의 문제점은 주기적으로 수행하는 memset이였다.  
그 memset의 배열 크기가 무지막지하게 큰게 원인이였다. 

무지막지하게 큰 memset을 처리하기 위해 Physical Memory에 해당 주소들을 매핑하게 되고 매핑정보를 TLB, Page Table에 차례대로 갱신하면서 기존에 메인 스레드에서 사용하던 매핑 정보가 모두 갱신되어 버리게 되었다.  
그럼 메인스레드에서는 TLB MiSS, Page Fault가 유발되면서 Disk에 접근을 해야하기 때문에 주기적인 성능 저하가 감지 되었다.  

수정은 초기화 여부를 판단하는 컬럼을 따로 두어 해당 값에 따라 동작을 구분하였다. (모든 정보가 memset되어야 할 필요가 없었으며, 단순히 상태정보를 표시하는 것으로 정상 동작이 가능한 부분이다.)

만약 진짜 모든 정보들이 memset이 되어야 하는 상황이라면 방법이 없을까?  
CPU의 경우는 각 코어마다 캐시가 있는 형태였고, 전역변수를 지역변수 형태로 변환하면서 지역성에 의한 문제를 유발하지 않는 형태로 개선했던것 처럼 뭔가 page fault상황을 무마시킬수는 없을까?

아쉽게도 아직 그런 방법은 찾지 못했다. (page의 크기 조정 등을 수행하며 시험해봤지만 의미 있는 데이터는 아니였다.)
Page Table이 뭔가 코어별로 처리된다던가... 하는 특별한 옵션등이 있는지도 아직 다 파악하지 못했다.

우선 확실한건 사이즈가 큰 변수에 대해 memory copy와 같은 동작을 하는것은 상당한 부하 요소이며 해당 스레드외에도 다른 스레드까지 성능의 영향을 준다는 점을 인지하고 개발할 필요가 있고, 그런 코딩은 '지양' 해야 한다는 점이다.


[참고사항 - schrodinger's Packet Drop](https://medium.com/niometrics-tech-blog/schrodingers-packet-drops-e1556af3e228)


