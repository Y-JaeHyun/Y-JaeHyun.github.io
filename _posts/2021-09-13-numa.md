---
layout:     post
author:     bcnote3314
title:  성능을 올리기 위한 삽질 기록
subtitle: NUMA(Non-Uniform Memory Access)
category: Experiences
---

# 개요

VTune이 제공 해준 성능 부하 2번째 컨텐츠는 NUMA 이다.  
NUMA 구조를 활용하기 위한 기본 개념이랑 관련 명령어등에 대해서 정리 한다.  


# NUMA

NUMA(Non Uniform Memeory Access)는 멀티 프로세서 시스템에서 사용되는 메모리 설계 방법이다.  
멀티 프로세서, 즉 CPU가 두개 이상인 시스템에서 메모리 접근을 어떻게 효율적으로 할수 있을까?  

이전 [Post](https://bcnote3314.github.io/experiences/2021/09/10/%EB%A9%94%EB%AA%A8%EB%A6%AC-%EC%A0%95%EB%A6%AC/) 에서 이미 캐시에 대한 이야기를 다루며 메모리 접근 속도에 대해서 간접적으로 이야기 한바가 있다.  
메모리 접근 속도의 한계가 있기 때문에 CPU에 캐시를 두어 최대한 접근 횟수를 줄이기 위한 방법이었다.  

메모리 접근 속도에 의한 부하는 CPU가 2개 이상인 경우에 더욱 문제가 된다.  
CPU에서 메모리로 접근하는 통로가 한개일 때 1번 CPU가 메모리에 접근하여 사용중이라면 2번 메모리는 메모리 접근이 불가능하여 놀고 있게된다.  
이런 문제점을 각각의 CPU에 독립적인 메모리 영역을 구분하여 제공하는 하는 방법을 통해 해결하려 하는것이 NUMA이다.  

!이미지 : https://rockball.tistory.com/entry/Numa%EC%9D%98-%EC%9D%B4%ED%95%B4!

각각의 CPU가 자신의 Local Memory를 두기 때문에 다른 CPU와 충돌로 인하여 대기하는 일이 없어질 수 있다.  
하지만 모든 해결책이 그러하듯(?) NUMA 역시도 한계가 있다.

예를들어 1번 CPU에 속하는 코어에 할당되어 동작하는 스레드에서 전역 변수에 접근하려고하는데 해당 전역 변수는 2번 CPU의 Local Memory에 존재한다고 하면 어떻게 접근을 해야할까?

직접 접근을 못하기 때문에 2번 CPU가 사용하지 않을때 Remote로 접근할 수 밖에 없으며 이는 성능에 좋지 않은 영향을 준다.  
최대한 Local Memory를 사용해도록 신경을 써야한다.  
(VTune에서는 메모리 접근 과정을 분석해서 Local 접근과 Remote접근 횟수에 대한 정보를 제공해주기 때문에 어떤 위치에서 Remote Memory 접근을 많이하는지 볼수 있다.)

# NUMA Policy

# NUMA API

# 메모리 


