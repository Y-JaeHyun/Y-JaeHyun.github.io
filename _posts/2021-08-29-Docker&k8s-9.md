---
layout:     post
author:     bcnote3314
title: 라즈베리 파이에 쿠버네티스 설치
category: Note
tags: 		Docker&k8s
---

라즈베리 파이에 쿠버네티스에서 제공하는 클러스터를 구성하고 환경을 구축하려고 한다.  
kubeadm은 쿠버네티스가 제공하는 클러스터 구축 도구이다.  

개인적으로 사용하는 라즈베리파이 2대, 노트북 1대, PC 1대 총 4대의 Node 후보가 있다.  
우선 라즈베리파이4를 마스터 노드로 사용하여 여러노드를 복합적으로 운영해보는 것이 목적이다.  

그러기 위해서 가장 먼저 넘어야 할 과제가 라즈베리파이에 쿠버네티스 환경 구성을 하는 것이다.  
라즈베리파이는 일반적인 CPU 아키텍쳐와 조금 다른 부분이 있기 때문에 환경구성과정에서 특이사항이 많이 있다. 

# 환경 구성 과정

## 1. docker 설치

```bash 
sudo apt install -y docker.io
```

## 2. cgroup driver를 enable로 설정

```bash
sudo cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF
```

## 3. cgroup limit 설정

```bash
sudo sed -i '$ s/$/ cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1 swapaccount=1/' /boot/cmdline.txt
```

해당 설정 이후에는 재부팅이 필요함.

## 4. 쿠버네티스 설치

```bash
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
cat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF
sudo apt update && sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
```

## 5. 쿠버네티스 클러스터 생성

```bash
sudo kubeadm init --pod-network-cidr=10.244.0.0/16
```

정상적으로 생성되었다면 아래와 같은 메세지가 확인된다.  

```
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.1.10:6443 --token XXXXXXX.XXXXXXXXXXXXXXXXXXXXXXXXXXX \
        --discovery-token-ca-cert-hash sha256:XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
```

cgroup-xxxx missing 관련 에러가 발생한다면, 위에 진행한 cgroup limit 설정 및 재부팅 과정을 재확인 해봐야 한다.  
또한 마지막줄의 kubeadm join 관련 문구는 worker node에서 사용되기 때문에 잘 보관해야한다.  

추가로 kubectl 등의 명령을 편하게 쓰기 위해서는 config 정보를 홈디렉토리에 복사해야한다.

``` bash
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

systemctl daemon-reload
```

config까지 복사 했으면 이제 node정보를 확인할 수 있다.  

```bash
$ kubectl get nodes
NAME          STATUS     ROLES                  AGE   VERSION
raspberrypi   NotReady   control-plane,master   13m   v1.22.1
```

## 6. Flannel 설치

Flannel은 네트워크 플러그인이다.  
Flannel 외에도 calico와 같은 다양한 플러그인이 존재한다.  

```bash
kubectl apply -f https://github.com/coreos/flannel/raw/master/Documentation/kube-flannel.yml
```

위 명령어로 flannel을 설치하고 나면 node 조회시 NotReady 상태였던 node가 Ready로 변경된것을 볼 수 있으며 환경 구성이 정상적으로 되었는지 kube-system 조회를 통해 확인 할수 있다.  
쿠버네티스 관련 pod들이 Running 상태인것을 보면된다.  

```bash
sudo kubectl get nodes -n kube-system
NAME          STATUS   ROLES                  AGE     VERSION
raspberrypi   Ready    control-plane,master   2d23h   v1.22.1

kubectl get pods -n kube-system
NAME                                  READY   STATUS    RESTARTS   AGE
coredns-78fcd69978-6hmmc              1/1     Running   0          2d23h
coredns-78fcd69978-tdj52              1/1     Running   0          2d23h
etcd-raspberrypi                      1/1     Running   0          2d23h
kube-apiserver-raspberrypi            1/1     Running   0          2d23h
kube-controller-manager-raspberrypi   1/1     Running   0          2d23h
kube-flannel-ds-hlj6n                 1/1     Running   0          3m23s
kube-proxy-c7zt4                      1/1     Running   0          2d23h
kube-scheduler-raspberrypi            1/1     Running   0          2d23h


```
